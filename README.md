# Fairness-and-Algorithmic-Decisions [reading list + notes]

**Article (#1)**: [AI Fairness Isn’t Just an Ethical Issue](https://hbr.org/2020/10/ai-fairness-isnt-just-an-ethical-issue) by Greg Satell and Yassmin Abdel-Magied (published on *Oct 20, 2020*)

**Article (#2)**: [Distributive Justice](https://plato.stanford.edu/entries/justice-distributive/) in the Stanford Encyclopedia of Philosophy (published on *Sep 22, 1996*)

##### Notes [Section 1-4]

Concept | Definition | Justifications | Challenges
--- | --- | --- | ---
Strict Egalitarianism | "Every person should have the same level of material goods (including burdens)" [[link]](https://plato.stanford.edu/entries/justice-distributive/) | People are morally equal so the distribution of material goods should reflect that. | (1) construction of appropriate indices of measurement (2) specification of time frames 
Pareto Superior Allocations | "Some allocations of material goods and services which will make some people better off without making anybody else worse off." [[link]](https://plato.stanford.edu/entries/justice-distributive/)| | 
Starting-gate Principles | "Principles specifying initial distributions after which the pattern need not be preserved" [[link]](https://plato.stanford.edu/entries/justice-distributive/)| | 
Difference Principle | "Social and economic inequalities are to be to the greatest benefit of the least advantaged members of society." [[link]](https://plato.stanford.edu/entries/justice-distributive/)| | 
Formal Equality of Opportunity | "... rules out formal discrimination on grounds such as a person’s race, ethnicity, age or gender" [[link]](https://plato.stanford.edu/entries/justice-distributive/)| | 

**Talk (#3)**: [The Trouble with Bias](https://www.youtube.com/watch?v=ggzWIipKraM) by Kate Crawford (at NIPS 2017 on *Dec 18, 2017*)

##### Notes

* Harm of allocation (resources) -> loan approval, etc. -> immediate, quantifiable, transactional
* Harms of representation (identity) -> ad delivery, google image labels, etc. -> long term, hard to formalize, cultural

**Paper (#4)**: Shah, Deven, H. Andrew Schwartz, and Dirk Hovy. "Predictive biases in natural language processing models: A conceptual framework and overview." arXiv preprint arXiv:1912.11078 (2019).

**Article (#5)**: [People Don't Actually Want Equality](https://www.theatlantic.com/science/archive/2015/10/people-dont-actually-want-equality/411784/) By Paul Bloom (published on *Oct 22, 2015*)
